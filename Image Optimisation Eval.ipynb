{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bfa26e28",
   "metadata": {},
   "source": [
    "# Image Preprocessing evaluation\n",
    "\n",
    "The goal of this experiment is to evaluate different methods of pre-processing the image before detection.\n",
    "\n",
    "Methods to be tested:\n",
    "\n",
    "- Nothing/Base;\n",
    "- black-white;\n",
    "- 8-bit color;\n",
    "- clusterisation into 256 colors;\n",
    "- clusterisation into 16 colors;\n",
    "- clusterisation into 8 colors.\n",
    "\n",
    "The main metrics we are concerned about are mAP@50, mAP@50-95 and FPS.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63efbae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "import glob\n",
    "import os\n",
    "import tempfile\n",
    "import shutil\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298904bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PLATE = YOLO(\"./yolo_plate.pt\")\n",
    "VAL_DIR = \"./Dataset V2/val/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd60ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define preprocessing functions\n",
    "def preprocess_base(img):\n",
    "    \"\"\"No preprocessing, return original image\"\"\"\n",
    "    return img.copy()\n",
    "\n",
    "\n",
    "def preprocess_black_white(img):\n",
    "    \"\"\"Convert to black and white\"\"\"\n",
    "    return cv2.cvtColor(cv2.cvtColor(img, cv2.COLOR_BGR2GRAY), cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "\n",
    "def preprocess_8bit_color(img):\n",
    "    \"\"\"Convert to 8-bit color (3 bits for R, 3 bits for G, 2 bits for B)\"\"\"\n",
    "    img_8bit = img.copy()\n",
    "    # Reduce color depth\n",
    "    img_8bit[:, :, 0] = (img_8bit[:, :, 0] >> 5) << 5  # Blue channel: 3 bits\n",
    "    img_8bit[:, :, 1] = (img_8bit[:, :, 1] >> 6) << 6  # Green channel: 2 bits\n",
    "    img_8bit[:, :, 2] = (img_8bit[:, :, 2] >> 5) << 5  # Red channel: 3 bits\n",
    "    return img_8bit\n",
    "\n",
    "\n",
    "def preprocess_cluster(img, n_clusters):\n",
    "    \"\"\"Color clustering using K-means\"\"\"\n",
    "    # Reshape the image to be a list of pixels\n",
    "    h, w, c = img.shape\n",
    "    reshaped = img.reshape((h * w, c))\n",
    "\n",
    "    # Apply k-means clustering\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)\n",
    "    labels = kmeans.fit_predict(reshaped)\n",
    "\n",
    "    # Replace each pixel with its centroid\n",
    "    clustered_img = kmeans.cluster_centers_[labels].reshape((h, w, c))\n",
    "    return clustered_img.astype(np.uint8)\n",
    "\n",
    "\n",
    "def preprocess_cluster_16(img):\n",
    "    \"\"\"Cluster colors to 16 colors\"\"\"\n",
    "    return preprocess_cluster(img, 16)\n",
    "\n",
    "\n",
    "def preprocess_cluster_8(img):\n",
    "    \"\"\"Cluster colors to 8 colors\"\"\"\n",
    "    return preprocess_cluster(img, 8)\n",
    "\n",
    "\n",
    "def preprocess_cluster_4(img):\n",
    "    \"\"\"Cluster colors to 4 colors\"\"\"\n",
    "    return preprocess_cluster(img, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6670259e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_preprocessing(original_img, processed_img, method_name):\n",
    "    \"\"\"Visualize original and processed images side by side.\"\"\"\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(cv2.cvtColor(original_img, cv2.COLOR_BGR2RGB))\n",
    "    plt.title(\"Original\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(cv2.cvtColor(processed_img, cv2.COLOR_BGR2RGB))\n",
    "    plt.title(f\"Processed ({method_name})\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def measure_performance(preprocess_fn, test_images, model, num_runs=3):\n",
    "    \"\"\"Measure preprocessing and inference times.\"\"\"\n",
    "    processing_times = []\n",
    "    inference_times = []\n",
    "\n",
    "    for img_path in test_images:\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is None:\n",
    "            print(f\"Warning: Unable to read image {img_path}. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        # Measure preprocessing time\n",
    "        start_time = time.time()\n",
    "        processed_img = preprocess_fn(img)\n",
    "        preprocessing_time = time.time() - start_time\n",
    "\n",
    "        # Measure inference time (average of num_runs)\n",
    "        total_inference_time = 0\n",
    "        for _ in range(num_runs):\n",
    "            start_time = time.time()\n",
    "            result = model(processed_img)\n",
    "            total_inference_time += time.time() - start_time\n",
    "        avg_inference_time = total_inference_time / num_runs\n",
    "\n",
    "        processing_times.append(preprocessing_time)\n",
    "        inference_times.append(avg_inference_time)\n",
    "\n",
    "    # Calculate speed metrics\n",
    "    avg_preprocessing_time = (\n",
    "        sum(processing_times) / len(processing_times) if processing_times else 0\n",
    "    )\n",
    "    avg_inference_time = (\n",
    "        sum(inference_times) / len(inference_times) if inference_times else 0\n",
    "    )\n",
    "    fps = (\n",
    "        1.0 / (avg_preprocessing_time + avg_inference_time)\n",
    "        if (avg_preprocessing_time + avg_inference_time) > 0\n",
    "        else 0\n",
    "    )\n",
    "\n",
    "    return avg_preprocessing_time, avg_inference_time, fps\n",
    "\n",
    "\n",
    "def create_validation_dataset(preprocess_fn, val_dir, temp_dir):\n",
    "    \"\"\"Create a temporary validation dataset with preprocessed images.\"\"\"\n",
    "    # Copy all label files\n",
    "    for label_file in glob.glob(os.path.join(val_dir, \"*.txt\")):\n",
    "        if os.path.basename(label_file) == \"classes.txt\":\n",
    "            continue  # Skip classes.txt if present\n",
    "        shutil.copy(label_file, temp_dir)\n",
    "\n",
    "    # Preprocess and save images\n",
    "    for img_file in glob.glob(os.path.join(val_dir, \"*.png\")):\n",
    "        img = cv2.imread(img_file)\n",
    "        if img is not None:\n",
    "            processed_img = preprocess_fn(img)\n",
    "            cv2.imwrite(\n",
    "                os.path.join(temp_dir, os.path.basename(img_file)), processed_img\n",
    "            )\n",
    "\n",
    "\n",
    "def create_dataset_config(val_dir, temp_dir):\n",
    "    \"\"\"Create a YAML configuration file for the dataset.\"\"\"\n",
    "    yaml_path = os.path.join(temp_dir, \"dataset.yaml\")\n",
    "\n",
    "    # Get list of class names if available\n",
    "    class_names = []\n",
    "    classes_file = os.path.join(val_dir, \"classes.txt\")\n",
    "    if os.path.exists(classes_file):\n",
    "        with open(classes_file, \"r\") as f:\n",
    "            class_names = [line.strip() for line in f.readlines()]\n",
    "    else:\n",
    "        # Default to generic class name\n",
    "        class_names = [\"object\"]\n",
    "\n",
    "    # Create YAML content\n",
    "    dataset_config = {\n",
    "        \"path\": temp_dir,  # Dataset root directory\n",
    "        \"train\": \"\",  # No train images in validation\n",
    "        \"val\": temp_dir,  # Validation images\n",
    "        \"test\": \"\",  # No test images\n",
    "        \"names\": {i: name for i, name in enumerate(class_names)},\n",
    "    }\n",
    "\n",
    "    # Write YAML file\n",
    "    with open(yaml_path, \"w\") as f:\n",
    "        yaml.dump(dataset_config, f)\n",
    "\n",
    "    return yaml_path\n",
    "\n",
    "\n",
    "def evaluate_preprocessing(preprocess_fn, name, val_dir, model, num_runs=3):\n",
    "    \"\"\"\n",
    "    Evaluates preprocessing method on validation images with labels.\n",
    "\n",
    "    Args:\n",
    "        preprocess_fn: preprocessing function to apply\n",
    "        name: name of the preprocessing method\n",
    "        val_dir: validation directory containing images and labels\n",
    "        model: YOLO model to use for detection\n",
    "        num_runs: number of runs for FPS calculation\n",
    "\n",
    "    Returns:\n",
    "        dict: metrics including mAP and FPS\n",
    "    \"\"\"\n",
    "    # First calculate speed metrics (FPS) on individual images\n",
    "    test_images = glob.glob(os.path.join(val_dir, \"*.png\"))[\n",
    "        :10\n",
    "    ]  # Limit to 10 images for speed test\n",
    "\n",
    "    # Example image visualization\n",
    "    if test_images:\n",
    "        img_path = test_images[0]\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is not None:\n",
    "            processed_img = preprocess_fn(img)\n",
    "            visualize_preprocessing(img, processed_img, name)\n",
    "\n",
    "    # Measure processing and inference times\n",
    "    avg_preprocessing_time, avg_inference_time, fps = measure_performance(\n",
    "        preprocess_fn, test_images, model, num_runs\n",
    "    )\n",
    "\n",
    "    # Run model validation on the entire validation set with preprocessing\n",
    "    with tempfile.TemporaryDirectory() as temp_dir:\n",
    "        # Create preprocessed validation dataset\n",
    "        create_validation_dataset(preprocess_fn, val_dir, temp_dir)\n",
    "\n",
    "        # Create dataset configuration\n",
    "        yaml_path = create_dataset_config(val_dir, temp_dir)\n",
    "\n",
    "        # Run validation on the preprocessed dataset\n",
    "        results = model.val(data=yaml_path, project=\"preprocessing_eval\", name=name)\n",
    "\n",
    "        # Extract metrics\n",
    "        metrics = {}\n",
    "        if hasattr(results, \"results_dict\"):\n",
    "            metrics = results.results_dict\n",
    "\n",
    "    return {\n",
    "        \"name\": name,\n",
    "        \"mAP50\": metrics.get(\"metrics/mAP50(B)\", 0),\n",
    "        \"mAP50-95\": metrics.get(\"metrics/mAP50-95(B)\", 0),\n",
    "        \"preprocessing_time\": avg_preprocessing_time,\n",
    "        \"inference_time\": avg_inference_time,\n",
    "        \"fps\": fps,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15333af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list to store evaluation results\n",
    "eval_results = []\n",
    "\n",
    "# Evaluate each preprocessing method\n",
    "preprocessing_methods = [\n",
    "    (preprocess_base, \"Base (No preprocessing)\"),\n",
    "    (preprocess_black_white, \"Black-White\"),\n",
    "    (preprocess_8bit_color, \"8-bit Color\"),\n",
    "    # (preprocess_cluster_16, \"Color Clustering (16 colors)\"),\n",
    "    (preprocess_cluster_8, \"Color Clustering (8 colors)\"),\n",
    "    (preprocess_cluster_4, \"Color Clustering (4 colors)\"),\n",
    "]\n",
    "\n",
    "for preprocess_fn, name in preprocessing_methods:\n",
    "    print(f\"Evaluating {name}...\")\n",
    "    result = evaluate_preprocessing(\n",
    "        preprocess_fn, name, VAL_DIR, MODEL_PLATE, num_runs=5\n",
    "    )\n",
    "    eval_results.append(result)\n",
    "    print(\n",
    "        f\"Completed {name} evaluation with results: mAP50={result['mAP50']:.4f}, FPS={result['fps']:.2f}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4459d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize results\n",
    "def plot_metrics(eval_results):\n",
    "    \"\"\"Plot comparison of preprocessing methods\"\"\"\n",
    "    # Create a figure with multiple subplots\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "    # Extract data for plotting\n",
    "    names = [r[\"name\"] for r in eval_results]\n",
    "    map50 = [r[\"mAP50\"] for r in eval_results]\n",
    "    map50_95 = [r[\"mAP50-95\"] for r in eval_results]\n",
    "    fps = [r[\"fps\"] for r in eval_results]\n",
    "    preproc_time = [r[\"preprocessing_time\"] for r in eval_results]\n",
    "\n",
    "    # Plot mAP50\n",
    "    axes[0, 0].bar(names, map50, color=\"skyblue\")\n",
    "    axes[0, 0].set_title(\"mAP50\")\n",
    "    axes[0, 0].set_ylim(0, 1.0)\n",
    "    plt.setp(axes[0, 0].get_xticklabels(), rotation=45, ha=\"right\")\n",
    "\n",
    "    # Plot mAP50-95\n",
    "    axes[0, 1].bar(names, map50_95, color=\"lightgreen\")\n",
    "    axes[0, 1].set_title(\"mAP50-95\")\n",
    "    axes[0, 1].set_ylim(0, 1.0)\n",
    "    plt.setp(axes[0, 1].get_xticklabels(), rotation=45, ha=\"right\")\n",
    "\n",
    "    # Plot FPS\n",
    "    axes[1, 0].bar(names, fps, color=\"salmon\")\n",
    "    axes[1, 0].set_title(\"Frames Per Second (FPS)\")\n",
    "    plt.setp(axes[1, 0].get_xticklabels(), rotation=45, ha=\"right\")\n",
    "\n",
    "    # Plot preprocessing time\n",
    "    axes[1, 1].bar(names, preproc_time, color=\"purple\")\n",
    "    axes[1, 1].set_title(\"Preprocessing Time (seconds)\")\n",
    "    plt.setp(axes[1, 1].get_xticklabels(), rotation=45, ha=\"right\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Create a summary table\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    cell_text = []\n",
    "    for r in eval_results:\n",
    "        cell_text.append(\n",
    "            [\n",
    "                r[\"name\"],\n",
    "                f\"{r['mAP50']:.4f}\",\n",
    "                f\"{r['mAP50-95']:.4f}\",\n",
    "                f\"{r['fps']:.2f}\",\n",
    "                f\"{r['preprocessing_time'] * 1000:.2f}\",\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    table = plt.table(\n",
    "        cellText=cell_text,\n",
    "        colLabels=[\"Method\", \"mAP50\", \"mAP50-95\", \"FPS\", \"Preproc Time (ms)\"],\n",
    "        loc=\"center\",\n",
    "    )\n",
    "    table.auto_set_font_size(False)\n",
    "    table.set_fontsize(12)\n",
    "    table.scale(2, 2)\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(\"Preprocessing Methods Comparison\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Plot the results\n",
    "plot_metrics(eval_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8d9396",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze results to recommend preprocessing methods\n",
    "def recommend_methods(eval_results):\n",
    "    \"\"\"Recommend preprocessing methods based on different priorities\"\"\"\n",
    "    # Sort by different metrics\n",
    "    by_map50 = sorted(eval_results, key=lambda x: x[\"mAP50\"], reverse=True)\n",
    "    by_map50_95 = sorted(eval_results, key=lambda x: x[\"mAP50-95\"], reverse=True)\n",
    "    by_fps = sorted(eval_results, key=lambda x: x[\"fps\"], reverse=True)\n",
    "\n",
    "    # Get best balance (normalize and sum metrics)\n",
    "    for r in eval_results:\n",
    "        max_map50 = max(x[\"mAP50\"] for x in eval_results)\n",
    "        max_map50_95 = max(x[\"mAP50-95\"] for x in eval_results)\n",
    "        max_fps = max(x[\"fps\"] for x in eval_results)\n",
    "\n",
    "        r[\"balanced_score\"] = (\n",
    "            0.4 * r[\"mAP50\"] / max_map50\n",
    "            + 0.4 * r[\"mAP50-95\"] / max_map50_95\n",
    "            + 0.2 * r[\"fps\"] / max_fps\n",
    "        )\n",
    "\n",
    "    by_balanced = sorted(eval_results, key=lambda x: x[\"balanced_score\"], reverse=True)\n",
    "\n",
    "    print(\"Recommended preprocessing methods:\")\n",
    "    print(f\"Best accuracy (mAP50): {by_map50[0]['name']}\")\n",
    "    print(f\"Best accuracy (mAP50-95): {by_map50_95[0]['name']}\")\n",
    "    print(f\"Best speed (FPS): {by_fps[0]['name']}\")\n",
    "    print(f\"Best balance of accuracy and speed: {by_balanced[0]['name']}\")\n",
    "\n",
    "\n",
    "recommend_methods(eval_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
